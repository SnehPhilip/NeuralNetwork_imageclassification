{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6CUnAyTZFZMtTBVzH5GQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnehPhilip/NeuralNetwork_imageclassification/blob/main/How_To_ANN_on_FlattenedImage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Action and Toolkit\n",
        "--------------------\n",
        "##   Image Classification - using Flattened Deep ANN\n",
        "Dataset: 60000 grayscale images of 28X28 dimension from Fashion MNIST data"
      ],
      "metadata": {
        "id": "WujKz92fYR-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "TECHNICAL TOOLKIT\n",
        "\n",
        "     *   Import necessary libraries.\n",
        "- **NumPy** for numerical operations  \n",
        "- **TensorFlow / Keras** for building and training deep learning models  \n",
        "- **Matplotlib** for visualizations  \n"
      ],
      "metadata": {
        "id": "AbcIA75qYk85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 1.   DATASET SETUP:\n",
        "\n",
        "#### 1.2) **Load Dataset:**\n",
        "\n",
        "Load the **CIFAR100** or Fashion-MNIST dataset from Keras\n",
        "\n",
        "- `keras.datasets.cifar10.load_data()`\n",
        "- `keras.datasets.Fashion-MNIST.load_data()`\n",
        "\n",
        "\n",
        "and split it into:  \n",
        "\n",
        "- (`train_images`, `train_labels`) â†’ training set tuple\n",
        "- (`test_images`, `test_labels`) â†’ test set tuple\n",
        "\n",
        "\n",
        "#### 1.3) **Preprocess Data:**\n",
        "\n",
        "    *   Preprocess the data (normalize and reshape images, one-hot encode labels).\n",
        "\n",
        "#### 1.3.1) **Normalize Data:**\n",
        "\n",
        "    - `train_images = train_images / 255.0`\n",
        "    - `test_images = test_images / 255.0`\n",
        "    *  Verify the shapes of the processed data.\n",
        "    - `train_images.shape `\n",
        "\n",
        "    Scale pixel values from **0â€“255** to the range **0â€“1** for faster and more stable training.  \n",
        "\n",
        "    **Example:**  \n",
        "    - Before: a pixel value could be `200`  \n",
        "    - After: `200 / 255 â‰ˆ 0.78`  \n",
        "\n",
        "\n",
        "####1.3.2) **Reshape Data:** (Make compatible if grayscale image.Reqd only for CNN architecture)\n",
        "\n",
        "    - `train_images.reshape() fn`\n",
        "    - `test_images.reshape() fn`\n",
        "\n",
        "      Reshape images to 32Ã—32Ã—1 by adding a channel dimension, making them compatible with CNN layers.\n",
        "\n",
        "      Example:\n",
        "      Before: (60000, 28, 28) â†’ 60,000 grayscale images without channel info\n",
        "      After: (60000, 28, 28, 1) â†’ channel dimension (1) added for CNN input\n",
        "\n",
        "\n",
        "####1.3.3) **One-Hot Encode Labels:**\n",
        "\n",
        "    - `keras.utils.to_categorical()` fn\n",
        "\n",
        "    Convert class labels (numbers) into one-hot encoded vectors with 10 output classes, required for multi-class classification.\n",
        "\n",
        "    Example:\n",
        "    Original label: 3\n",
        "    One-hot encoded: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "    Convert class labels (0â€“99) into one-hot encoded vectors with 100 output classes, required for multi-class classification in case of CIFAR 100.\n",
        "\n",
        "\n",
        "####1.3.4) **Verify Dataset Shapes:**\n",
        "\n",
        "    Print the shapes of images and labels after preprocessing to confirm everything is in the expected format.\n",
        "    train_images.shape\n",
        "    test_images.shape\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G3WEOfg6YUBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. CREATE MODEL\n",
        "\n",
        "\n",
        "creates an empty neural network that can take in many layers.\n",
        "\n",
        "Layer-1 : Flatten layer converts the 28X28-D image into 784, 1-D sized array\n",
        "\n",
        "Layer-2 : Dense or Hidden layer with 128 neurons.(Activation fn Relu)\n",
        "\n",
        "Layer-3 : Dense or Hidden layer with 64 neurons.(Activation fn Relu)\n",
        "\n",
        "Layer-4 : Dense or Hidden layer with 10 neurons.Activatin fn Softmax (Multi class output layer with 10 one_hot label)\n",
        "\n",
        "\n",
        "**Adam** ,stochastic,gradientdescent etc : optimizers decides how  parameters are to be tuned."
      ],
      "metadata": {
        "id": "RK6wg81JazHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Technical Toolkit\n",
        "----------------------\n",
        " `keras.Sequential() fn`\n",
        "\n",
        "`ann_model.compile(optimizer='',loss='',metrics=['']) fn`\n",
        "\n",
        "`ann_model.summary() fn`"
      ],
      "metadata": {
        "id": "k8WvrCFaaknr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. TRAINING\n",
        "\n",
        "epoch ?\n",
        "\n",
        "One whole iteration of the entire dataset.\n",
        "Accuracy,Loss on train data ,Validation accuracy,validation loss on unseen data is checked after every epoch.\n",
        "\n",
        "batch size ?\n",
        "\n",
        "batch size 60 implies 60 images at a time or 60 rows at a time or 60 input output pairs at a time.Weights are updated once for each batch.The average error is calculated and weights are updated accordingly.\n",
        "\n",
        "If batch size=1 , in one epoch weights are updated 60000 times.\n",
        "\n",
        "If batch size=60 , in one epoch weights are updated 1000 times.\n",
        "\n",
        "If batch size=600 , in one epoch weights are updated 100 times.\n",
        "\n",
        "If batch size=60000, weights are updated just once. This may not be best accuracy. ( accuracy is seen as low as 36% )\n",
        "So if batch size is decreased we see weights are updated more number of times and accuracy improves.But when batch size is too small, again accuracy decreases.ie if batch size is 1, model learns for each image and leads to over fitting problem.\n",
        "\n",
        "If dataset samples are less in count ,batch size 1 is fine.(say if 2000 images batch size of 5 is fine.)\n",
        "\n",
        "Each time we modify batch size we see the training continues from the epoch cycle where it stopped.(until we re-initialize the model ie fit() again)\n",
        "\n",
        "\n",
        "- **EarlyStopping**: monitors validation loss, stops if no improvement for 5 epochs, restores best weights.  \n",
        "- **ModelCheckpoint**: saves best ANN weights (`best_ann_model_weights.weights.h5`) based on validation loss.  \n",
        "- **Training**:  \n",
        "  - Epochs: up to 30 (early stopping controls actual run)  \n",
        "  - Batch size: 64  \n",
        "  - Validation on test set  \n",
        "  - Callbacks: EarlyStopping + ModelCheckpoint  "
      ],
      "metadata": {
        "id": "u-N6UH3Zb710"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. EarlyStopping()\n",
        "\n",
        "This is a regularization technique used to prevent Overfitting.\n",
        "\n",
        "    monitor='val_loss': The model watches the error rate on the validation (test) data.\n",
        "\n",
        "    patience=5: If the validation loss does not improve for 5 consecutive epochs, the training stops automatically. This saves time and prevents the model from getting worse.\n",
        "\n",
        "    restore_best_weights=True: When training stops, the model rolls back to the weights that had the absolute lowest error, rather than keeping the \"overfitted\" weights from the final epoch.\n",
        "\n",
        "2. Model Checkpoint ()\n",
        "\n",
        "This is your \"Save Game\" feature.\n",
        "\n",
        "    save_best_only=True: It only overwrites the file if the current epoch's performance is better than the previous \"best.\"\n",
        "\n",
        "    mode='min': Since we are monitoring val_loss, \"best\" means the minimum value.\n",
        "\n",
        "    save_weights_only=True: It saves the numerical weights (w and b) rather than the entire model architecture, keeping the file size small (.h5 format).\n",
        "\n",
        "ðŸ“‰ The Training Process (ann_model.fit)\n",
        "\n",
        "    epochs=30\tThe maximum number of times the model will see the entire dataset.\n",
        "\n",
        "    batch_size=60\tThe model looks at 60 images at a time before updating its weights.\n",
        "\n",
        "    validation_data\tThe \"Hidden Exam.\" The model trains on train_images but checks its accuracy using test_images after every epoch.\n",
        "    \n",
        "    callbacks\tAttaches your Early Stopping and Checkpoint tools to the training loop.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MXyw3DnOeQ8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Technical Toolkit\n",
        "-----------------\n",
        "\n",
        "\n",
        "      ` model_object.fit() FN`\n",
        "\n",
        "      ` PARAMETERS - > training data, #epochs, #batch_size, validation_data, callbacks`   \n",
        "    \n",
        "        keras.callbacks.EarlyStopping()\n",
        "\n",
        "        keras.callbacks.ModelCheckpoint()\n",
        "\n",
        "        ann_model.fit()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GG8CLrTWisFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. EVALUATE MODEL\n",
        "\n",
        "\n",
        "Aim : To see how well the model performs on unseen data.\n",
        "evaluate() is used after training is completely finished to see how the model performs on a totally independent \"Hold-out\" dataset.(validation dataset)"
      ],
      "metadata": {
        "id": "Qxwx2vMfi9Ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Technical ToolKit\n",
        "-----------------\n",
        "\n",
        "`model_object.evaluate()` fn\n",
        "\n",
        "`ann_model.load_weights('.h5')` fn\n"
      ],
      "metadata": {
        "id": "pdzAo74lk57m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. PREDICT\n",
        "\n",
        "    The model takes your test_images and runs them through its layers.\n",
        "    It doesn't output a simple answer like \"Cat\" or \"Dog.\n",
        "    \n",
        "    Instead, it outputs a probability distribution for each image.\n",
        "\n",
        "    Example: If you have 3 classes (Cat, Dog, Bird), ann_predictions for one image might look like:\n",
        "    [0.1, 0.7, 0.2].\n",
        "    This means the model is 70% sure the image is a Dog.\n",
        "\n",
        "\n",
        "\n",
        "| Model Type | What `.predict()` returns | Example Output |\n",
        "| :--- | :--- | :--- |\n",
        "| **Classification (Deep Learning)** | A vector of class probabilities | `[0.1, 0.8, 0.1]` |\n",
        "| **Simple Classifiers (sklearn)** | The final predicted class label | `1` |\n",
        "| **Regression** | A continuous numerical value | `250500.0` |\n",
        "\n",
        "\n",
        "    Convert to Readable Prediction format\n",
        "    -------------------------------------\n",
        "    \n",
        "    `Ylabels_int = np.argmax(Ylabels_onehot)`\n",
        "\n",
        "            What's happening:  actual labels are likely in One-Hot Encoded format (e.g., a Dog is [0, 1, 0]).\n",
        "\n",
        "            The Conversion: np.argmax(..., axis=1) finds the index of the highest value.\n",
        "\n",
        "            Why? To compare the model's performance later, we need a simple integer (e.g., 1 for Dog) rather than a list of zeros and ones.\n",
        "\n",
        "    `PredLabels_int = np.argmax(PredLabels_prob)`\n",
        "\n",
        "            What's happening: Similar to the step above, we apply argmax to the model's probabilistic output.\n",
        "\n",
        "            example [0.1, 0.7, 0.2], the highest value is at index 1.\n",
        "\n",
        "            So this line converts the \"fuzzy\" probabilities into a final, definitive guess (the predicted class).\n",
        "\n",
        "### Technical Toolkit\n",
        "\n",
        "\n",
        "    `  model_object.predict()`\n",
        "\n",
        "    ` test_labels_int = np.argmax(test_labels_one_hot, axis=1)`\n",
        "\n",
        "    ` ann_predicted_labels = np.argmax(ann_predictions, axis=1)`\n",
        "\n"
      ],
      "metadata": {
        "id": "r9PpD6mSiyHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. SUMMARY TABLE\n",
        "\n",
        "  1. Confusion matrix\n",
        "\n",
        "         `cm_matrix_raw = confusion_matrix(Ylabels_int, PredLabels_int)`\n",
        "\n",
        "  2. Matplotlib ðŸ“ˆ Core Visualization Capabilities\n",
        "\n",
        "  Helps to convert boring numbers to graphs.\n",
        "  if x=[1,2,3] y=[4,5,6] is the data plt.plot(x,y) gives a graph of it.\n",
        "\n",
        "  | **Chart Type**|Function|Best Use Case\n",
        "  | :--- | :--- | :--- |\n",
        "  |**Line Graph**|plt.plot(x, y)|Tracking Loss/Accuracy over epochs.\n",
        "  |**Bar Chart**|plt.bar(x, y)|Comparing performance across different models.\n",
        "  |**Pie Chart**|plt.pie(data)|Visualizing class distribution in a dataset.\n",
        "  |**Scatter Plot**|plt.scatter(x, y)|Identifying clusters or outliers in latent space.\n",
        "\n",
        "\n",
        "\n",
        "  3. Seaborn Heatmaps\n",
        "\n",
        "\n",
        "    * **Definition:** A data visualization technique of arranging the magnitude of data points through a spectrum of colors.\n",
        "    * **Structure:** The data is presented as a **2D grid or map**, making it easy to cross-reference categories.\n",
        "    * **Color Scale:** Usually, **red/orange** represents high intensity or frequency, while **blue/purple** represents low intensity.\n",
        "    * **Purpose:** It allows for the immediate  pattern recognitions, or time series visualization correlation analysis[errors (such as misclassifications in a confusion matrix).]"
      ],
      "metadata": {
        "id": "NdNJaeQdoGJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technical Toolkit\n",
        "---------------------------------\n",
        "\n",
        "- cm_ann = confusion_matrix()\n",
        "- fig, axis = plt.subplots(figsize=(18, 5))\n",
        "- sns.heatmap(cm_ann, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axis)\n",
        "- axis.set_title(\"ANN Model\")\n",
        "- axis.set_xlabel(\"Predicted\")\n",
        "- axis.set_ylabel(\"Actual\")\n",
        "- plt.tight_layout()\n",
        "- plt.show()"
      ],
      "metadata": {
        "id": "P6DuquKa3uCi"
      }
    }
  ]
}